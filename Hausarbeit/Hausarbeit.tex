\documentclass[12pt,a4paper]{scrreprt}

\usepackage[margin=2.5cm]{geometry}
\usepackage[onehalfspacing]{setspace}
\usepackage{placeins}
\KOMAoptions{parskip=half}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{microtype} % Verbessert Blocksatz
\hyphenpenalty=5000 % Reduziert Silbentrennung stark
\exhyphenpenalty=5000 % Reduziert Trennung nach expliziten Bindestrichen
\tolerance=1000 % Erlaubt etwas mehr Wortabstand statt Trennung



% ---------- Seitenstil / Kopf-/Fußzeilen ----------
\usepackage[automark]{scrlayer-scrpage}
\usepackage{pageslts}
\usepackage{refcount}
\usepackage{tocbasic}
\usepackage{enumitem}
\usepackage{booktabs}

% Verzeichnis-Überschriften ohne Extra-Abstände und mit gleichem Pagestyle
\AfterTOCHead[lof]{%
  \thispagestyle{scrheadings}%
  \markboth{\listfigurename}{\listfigurename}%
}
\AfterTOCHead[lot]{%
  \thispagestyle{scrheadings}%
  \markboth{\listtablename}{\listtablename}%
}
\AfterTOCHead[lol]{%
  \thispagestyle{scrheadings}%
  \markboth{\lstlistlistingname}{\lstlistlistingname}%
}

\clearpairofpagestyles
\ihead{}\chead{}\ohead{}
\cfoot*{\pagemark}
\setkomafont{pageheadfoot}{\normalfont}
\KOMAoptions{headsepline=false,plainheadsepline=false}
\pagestyle{scrheadings}
\renewcommand*{\chapterpagestyle}{scrheadings}

% LoF/LoT in das Inhaltsverzeichnis (kein \addcontentsline nötig)
\KOMAoptions{listof=totoc}

% ---------- Sprache/Fonts ----------
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

% ---------- Mathe & Einheiten ----------
\usepackage{amsmath,amssymb}
\usepackage{siunitx}
\sisetup{detect-all}

% ---------- Grafiken & Tabellen ----------
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage[labelfont=bf,labelsep=colon,justification=raggedright,singlelinecheck=false]{caption}
\KOMAoptions{captions=tableheading}
\usepackage{subcaption}
\usepackage{array}

% --- Listings (X++) ---------------------------------------------------------
\usepackage{listings}
\usepackage{float}
\usepackage[dvipsnames]{xcolor}
\usepackage{chngcntr}
\counterwithout{table}{chapter}

\definecolor{kommentargruen}{HTML}{008000}
\definecolor{publicstaticblau}{HTML}{1e90ff}
\definecolor{namenteal}{HTML}{008b8b}
\definecolor{codegreen}{rgb}{0,0.6,0}
\usepackage{ragged2e}

\renewcommand{\lstlistingname}{Listing}
\renewcommand{\lstlistlistingname}{Listingsverzeichnis}

% X++-Sprache definieren
\lstdefinelanguage{XPP}{
  morekeywords=[1]{},
  morekeywords=[2]{while, select},
  morekeywords=[3]{myTable},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[s]{/*}{*/},
  morestring=[b]",
  alsoletter={_}
}

% Stil für X++
\lstdefinestyle{xppstyle}{
  language=XPP,
  basicstyle=\ttfamily\small,
  numbers=left,
  numberstyle=\tiny,
  numbersep=6pt,
  frame=single,
  showstringspaces=false,
  columns=fullflexible,
  keepspaces=true,
  tabsize=4,
  breaklines=true,
  breakatwhitespace=true,
  keywordstyle=[1]\color{kommentargruen}\bfseries,
  keywordstyle=[2]\color{publicstaticblau}\bfseries,
  keywordstyle=[3]\color{namenteal}\bfseries,
  commentstyle=\color{Gray}\itshape,
  stringstyle=\color{namenteal}
}

\lstdefinelanguage{XML}{
  morestring=[b]",
  morecomment=[s]{<!--}{-->},
  moredelim=[s][\color{blue}]{<}{>},
  stringstyle=\color{orange},
  identifierstyle=\color{black},
}

\lstdefinestyle{xmlstyle}{
  basicstyle=\ttfamily\small,
  numbers=left,
  numberstyle=\tiny,
  numbersep=8pt,
  breaklines=true,
  frame=single,
  captionpos=b
}

% Listings global
\lstset{
  float=false,          % nicht floaten -> bleibt im Fließtext
  captionpos=b,
  style=xppstyle,
  frame=none
}

% Nur Verzeichniseintrag ohne Code im Text:
\newcommand{\xpponlylist}[2]{% #1 Caption, #2 Label
  \refstepcounter{lstlisting}%
  \addcontentsline{lol}{lstlisting}{\protect\numberline{\thelstlisting}#1}%
  \label{#2}%
}


% ---------------------------------------------------------------------------

\usepackage{csquotes}

% ---- biblatex ----
\usepackage[
  backend=biber,
  style=iso-numeric,
  sorting=none,
  autocite=inline
]{biblatex}

% Treiber-Aliasse, damit keine Warnungen für exotische Typen kommen
\DeclareBibliographyAlias{legislation}{misc}
\DeclareBibliographyAlias{standard}{book}



\addbibresource{literatur.bib}

\usepackage[
  colorlinks=true,
  linkcolor=black,
  urlcolor=blue,
  citecolor=black,
  anchorcolor=black,
  breaklinks=true
]{hyperref}

% ---- Warnung von tracklang gezielt filtern (statt fehlerhafter Option) ----
\usepackage{silence}
\WarningFilter{tracklang}{No `datatool' support for dialect}

% ---- glossaries ----
%\usepackage[xindy,acronym]{glossaries}
%\IfFileExists{glossar.tex}{\loadglsentries{glossar.tex}}{\typeout{*** glossar.tex NICHT gefunden ***}}
%\makeglossaries
%\GlsSetXdyLanguage{german}
%\setacronymstyle{long-short}

% --- tocloft ENTFERNT ---

% ---- Metadaten ----
\newcommand{\Titel}{Hausarbeit zur Singulärwertzerlegung}
\newcommand{\Art}{Hausarbeit}
\newcommand{\Autor}{Malte Luca Peukert}
\newcommand{\Anschrift}{Beethovenstraße 27, 06749 Bitterfeld-Wolfen}
\newcommand{\Seminargruppe}{CS24-1}
\newcommand{\Matrikelnummer}{5002722}
\newcommand{\Betreuer}{}
\newcommand{\FirmaDesBetreuer}{Kunert Business Software GmbH}
\newcommand{\AdresseFirma}{Altenburger Str. 13, 04275 Leipzig}
\newcommand{\OrtDatum}{Leipzig, 28. Dezember 2025}
\newcommand{\blockcite}[2]{%
  \begin{displayquote}
    \enquote{#1}%
    \par\small\raggedleft
    \citeauthor{#2} (\citeyear{#2}): \citetitle{#2}.%
  \end{displayquote}
}

% Kapitel-/Abschnittsabstände vereinheitlicht

\setkomafont{chapter}{\Large\bfseries}
\setkomafont{section}{\large\bfseries}
\setkomafont{subsection}{\normalsize\bfseries}

\RedeclareSectionCommand[
  style=section, 
  indent=0pt, 
  beforeskip=0pt,
  afterskip=.8\baselineskip,
  afterindent=false
]{chapter} 

\RedeclareSectionCommand[
  beforeskip=.8\baselineskip,
  afterskip=.5\baselineskip,
  afterindent=false
]{section}
\RedeclareSectionCommand[afterindent=false]{subsubsection}

\begin{document}
\pagenumbering{gobble}

\begin{titlepage}
  \centering
  \Large
  Duale Hochschule Sachsen\\[0.5em]
  Staatliche Studienakademie Leipzig\\[4em]
  \huge\bfseries \Titel\\[1cm]
  \small
  im Rahmen des Studiengangs Bachelor of Science\\
  in der Studienrichtung Informatik\\
  im Modul Algorithmen und Datenstrukturen (5CS-TI2AD-30)

  \vspace{3cm}

  \begin{center}
    \normalsize
    \begin{tabularx}{\linewidth}{l X}
      Eingereicht von: & \Autor \\
                        & \Anschrift \\
                        & Seminargruppe: \Seminargruppe \\
                        & Matrikelnummer: \Matrikelnummer \\[1cm]
    \end{tabularx}
    \vspace{1cm}
  \end{center}

  \vfill
  \begin{center}
    \OrtDatum
  \end{center}
\end{titlepage}


\begingroup
  \KOMAoptions{headsepline=false,plainheadsepline=false}
  \setcounter{tocdepth}{1}% Kapitel + Abschnitte, damit das Inhaltsverzeichnis auf eine Seite passt
  \pagestyle{empty}
  \tableofcontents
\endgroup

\cleardoublepage



% HIER HAUPTTEIL
\pagenumbering{arabic}
\setcounter{page}{1}
\chapter{Einleitung}
In unserer digitalisierten Welt sind Bilder allgegenwärtig. Durch die Weiterentwicklung von Mobiltelefonen hat so gut wie jeder eine hochauflösende Kamera in der Hosentasche. Mit dieser steigenden Auflösung wächst der Bedarf an effizienter Speicherung und Übertragung. Dafür ist es notwendig, wirksam und zuverlässig Bilddaten zu komprimieren. Klassische Verfahren, wie zum Beispiel JPEG oder PNG, nutzen mathematische Transformation, um redundante Informationen zu entfernen und damit den Speicherbedarf signifikant zu reduzieren. Ein besonders effektives und effizientes mathematisches Verfahren ist dafür die Singulärwertzerlegung (Singular Value Decomposition, SVD) \cite{hansen1987svd}. Sie hat große Bedeutung für die Bildverarbeitung, aber auch weitreichende Anwendungen in der Signalverarbeitung, Datenanalyse, Statistik und maschinellen Lernen \cite{golub_svd}.

Die SVD ist ein zentrales Konzept der linearen Algebra \cite{strang_ocw}. Besonders relevant für Bildkompression ist ihre Eigenschaft, Matrizen optimal durch niedrigere Ränge approximieren zu können. Diese Tatsache ist im sogenannten Eckart-Young-Theorem formalisiert und dient bis heute als Grundlage zahlreicher Kompressionsverfahren \cite{eckart_young}.

Diese Hausarbeit untersucht die Anwendung der SVD zur Speicherung eines vereinfachten Bildes und zeigt, wie mithilfe der Rang-k-Approximation Speicherplatz reduziert werden kann, ohne die wesentlichen Bildinformationen zu verlieren.
\chapter{Problemstellung}
Hochauflösende digitale Bilder bestehen aus einer großen Anzahl von Pixeln, die üblicherweise als eine zweidimensionale Matrix gespeichert werden. Dementsprechend wächst der Speicherbedarf eines unkomprimierten Bildes proportional zur Anzahl der Pixel. Bei einer Größe von 15x25 enthält die Matrix bereits 375 einzelne Werte, während ein Bild im HD-Format bereits über zwei Millionen Pixel umfasst. 

Die zugrunde liegende Aufgabe dieser Arbeit besteht darin,
\begin{enumerate}
    \item die Matrixdarstellung des Buchstabens „F“ aus einer Textdatei einzulesen,
    \item die vollständige SVD dieser Matrix zu berechnen,
    \item die sukzessiven Rang-k-Approximationen zu erzeugen und zu analysieren,
    \item die Veränderung der Bildqualität bei zunehmendem k zu untersuchen, und
    \item die erzielten Speicherersparnisse gegenüber der Originalmatrix zu bestimmen.
\end{enumerate}

Das zugrunde liegende Ziel ist es, zu verstehen, wie stark ein Bild komprimiert werden kann, ohne an Erkennbarkeit oder Informationswert zu verlieren.

\chapter{Mathematische Grundlagen der SVD}
\section{Grundlagen der Matrixdarstellung von Bildern}
Ein Graustufenbild lässt sich mathematisch als Matrix
\[
  A \in \mathbb{R}^{m \times n}
\]
darstellen. Jeder Eintrag $a_{ij}$ stellt dabei den Helligkeitswert eines Pixels dar. Binäre Bilder, wie das in dieser Hausarbeit benutzte „F", enthalten nur die Werte 0 und 1. Sie eignen sich trotzdem hervorragend zur Untersuchung von Strukturzerlegung, da sie klare Kanten und Zusammenhänge besitzen.

\section{Definition der Singulärwertzerlegung}
Die SVD zerlegt eine Matrix $A$ in drei Komponenten:
\[
  A = U \Sigma V^{T}
\]
Dabei gelten folgende Eigenschaften:
\begin{itemize}
    \item $U \in \mathbb{R}^{m \times m}$ enthält die orthogonalen Basisvektoren der Zeilenstruktur.
    \item $\Sigma \in \mathbb{R}^{m \times n}$ enthält die Singulärwerte $\sigma_1 \ge \sigma_2 \ge \dots$.
    \item $V \in \mathbb{R}^{n \times n}$ enthält die orthogonalen Basisvektoren der Spaltenstruktur.
\end{itemize}

Jeder Singulärwert $\sigma_i$ in $\Sigma$ gibt die Bedeutung des zugehörigen Basisvektors an. Größere Werte deuten auf wichtigere Strukturen hin, während kleinere Werte oft Rauschen beziehungsweise weniger relevante Details repräsentieren.

\section{Rang-k-Approximation}
Die entscheidende Eigenschaft der SVD für die Bildkompression ist die Möglichkeit, eine Matrix $A$ durch eine Rang-k-Approximation $A_k$ zu nähern:
\[
  A_k = U_k \Sigma_k V_k^{T}
\]
Hierbei werden nur die ersten $k$ Singulärwerte und die zugehörigen Spalten von $U$ und $V$ verwendet. Diese Approximation minimiert den Frobenius-Norm-Fehler zwischen $A$ und $A_k$, was bedeutet, dass $A_k$ die bestmögliche Annäherung an $A$ mit Rang $k$ ist \cite{eckart_young}.

\section{Speicherersparnis durch Rang-k-Approximation}
Originalmatrix:
\[
  	\text{Speicherbedarf von } O = m \times n
\]

Die Speicherersparnis ergibt sich aus der Reduktion der benötigten Elemente zur Speicherung der Matrix. Anstatt die gesamte $m \times n$ Matrix $A$ zu speichern, müssen nur noch die ersten $k$-Spalten von $U$, die ersten $k$-Zeilen und Spalten von $\Sigma$ sowie die ersten $k$-Spalten von $V$ gespeichert werden. Die Gesamtanzahl der zu speichernden Elemente reduziert sich somit auf:
\[
  S(k) = k(m + n + 1)
\]
Dies führt zu einer erheblichen Reduktion des Speicherbedarfs, insbesondere wenn $k$ deutlich kleiner ist als $m$ und $n$.

Relative Speicherersparnis:
\[
  	\text{ Relative Speicherersparnis } E(k) = 1- \frac{S(k)}{O} = 1 - \frac{k(m + n + 1)}{m \times n}
\]

\chapter{Programmbeschreibung und Auswertung}
In diesem Kapitel wird das entwickelte Python-Programm \texttt{svd\_image\_compression.py} detailliert beschrieben. Das Programm dient der praktischen Umsetzung der Singulärwertzerlegung zur Bildkompression. Es ermöglicht das Einlesen einer Bildmatrix und die Berechnung der reduzierten SVD. Des Weiteren erzeugt es die Rekonstruktionen für verschiedene Rangwerte, die grafische Darstellung der Ergebnisse. Letztlich erfolgt die Berechnung von Fehlermaßen, sowie Energieerhaltung und der Speicherersparnis. Zusätzlich wird eine übersichtliche CSV-Datei zur Dokumentation der Ergebnisse erzeugt.

\section{Lösungsansatz und Wahl der Programmiersprache}
Zur praktischen Umsetzung wird Python in Verbindung mit der Bibliothek NumPy und Matplotlib verwendet. NumPy stellt eine hocheffiziente Implementierung der SVD bereit, die intern auf der LAPACK-Bibliothek basiert und Mathplotlib ermöglicht die anschauliche Visualisierung der Ergebnisse.

Python bietet darüber hinaus:
\begin{itemize}
    \item hohe Lesbarkeit und einfache Syntax,
    \item einfache Datenverarbeitung,
    \item Plattformunabhängigkeit,
    \item schnelle Umsetzung von mathematischen Algorithmen.
\end{itemize}

\section{Programmstruktur und Ablauf}
Das Programm ist klar modular aufgebaut und besteht aus drei Hauptbereichen:
\begin{enumerate}
    \item \textbf{Hilfsfunktionen} (Matrix-Einlesen, SVD, Rekonstruktion, Speicherersparnis, Fehlerberechnung)
    \item \textbf{Verarbeitungsfunktion} \texttt{process\_file} als zentrale Pipeline
    \item \textbf{Komandzeileninterface (CLI)} mit \texttt{argparse}
\end{enumerate}

Der grundsätzliche Ablauf des Programms ist wie folgt:
\begin{enumerate}
    \item Einlesen der Bildmatrix aus \texttt{SVD\_F.txt}.
    \item Berechnung der reduzierten Singulärwertzerlegung.
    \item Rekonstruktion der Bildmatrix für verschiedene Rangwerte $k$.
    \item Speicherung der rekonstruierten Matrizen als PNG-Dateien.
    \item Optionale Speicherung als Textdateien.
    \item Berechnung und Ausgabe von Fehlermaßen, Energieerhaltung und Speicherersparnis.
    \item Erzeugung einer CSV-Datei mit den Ergebnissen.
\end{enumerate}
\section{Einlesen der Bildmatrix}
Das Einlesen der Bilddaten erfolgt über die Funktion:
\begin{verbatim}
    def load_matrix(path: str):
\end{verbatim}
Die Matrix wird aus einer Textdatei eingelesen:
\begin{verbatim}
    A = np.loadtxt(path)
\end{verbatim}
Die Datei \texttt{SVD\_F.txt} enthält die binäre Matrix des Buchstabens „F“. Jeder Eintrag entspricht einem Pixelwert (0 oder 1). Nach dem Einlesen wird die Matrix in ein NumPy-Array vom Typ \texttt{float} umgewandelt, welches für die weitere Verarbeitung verwendet wird.

\section{Berechnung der Singulärwertzerlegung}
Die Funktion:
\begin{verbatim}
    def compute_svd(A: np.ndarray):
\end{verbatim}
berechnet die reduzierte SVD der Matrix $A$ mittels NumPy:
\begin{verbatim}
    U, S, Vt = np.linalg.svd(A, full_matrices=False)
\end{verbatim}
Die Zerlegung erfolgt gemäß der Definition:
\[
    A = U \Sigma V^{T}
\]
Dabei enthalten:
\begin{itemize}
    \item $U$: linke Singulärvektoren,
    \item $S$: Singulärwerte (als 1D-Array),
    \item $V^{T}$: transponierte rechte Singulärvektoren.
\end{itemize}
Die reduzierte Form (\texttt{full\_matrices=False}) sorgt dafür, dass nur die notwendigen Komponenten berechnet werden, was Speicher spart.

\section{Rekonstruktion der Rang-k-Approximation}
Die Rang-k-Approximation wird durch die Funktion:
\begin{verbatim}
    def reconstruct_rank_k(U: np.ndarray, S: np.ndarray, Vt: np.ndarray, k: int)
\end{verbatim}
berechntet. Die mathematische Umsetzung lautet:
\[
    A_k = U_k \Sigma_k V_k^{T}
\]
Dabei werden nur die ersten $k$-Spalten von $U$, die ersten $k$-Singulärwerte und die ersten $k$-Zeilen von $V^{T}$ verwendet. Die Implementierung erfolgt direkt als Matrixprodukt:
\begin{verbatim}
    return U[:, :k] @ np.diag(S[:k]) @ Vt[:k, :]
\end{verbatim}
Durch die vektorisierte Form ist die Rekonstruktion sowohl numerisch stabil als auch effizient.
Falls ein ungültiger Wert für $k$ übergeben wird, wird ein ValueError ausgelöst:
\begin{verbatim}
    if k <= 0:
      raise ValueError("k muss >= 1 sein")
\end{verbatim}

\section{Speicherung der Rekonstruktionen}
Die rekonstruierten Matrizen werden als Text gespeichert. Dies erfolgt in der Funktion:
\begin{verbatim}
    def save_reconstruction(Ak: np.ndarray, filename: str)
\end{verbatim}
Die Speicherung erfolgt mit:
\begin{verbatim}
    np.savetxt(filename, Ak, fmt="%.3f")
\end{verbatim}
Die Speicherung mit drei Nachkommastellen ermöglicht eine kompakte Dokumentation der Näherungsmatrix, mit Werten wie 0.000, 0.333, 0.667 und 1.000, in einer Textdatei entsprechend des jeweiligen $k$, wie z.B. \texttt{reconstruction\_k\_1.txt}.

\section{Fehlerberechnung (Frobenius-Norm)}
Die Rekonstruktionsqualität wird durch die Frobenius-Norm des Fehlers mit der Funktion gemessen:
\begin{verbatim}
    def reconstruction_error(A: np.ndarray, Ak: np.ndarray)
\end{verbatim}

Mathematisch wird der Fehler wie folgt definiert:
\[
  \| A - A_k \|_F 
\]
und implementiert mit:
\begin{verbatim}
    return float(np.linalg.norm(A - Ak, ord='fro'))
\end{verbatim}
Diese Norm misst die quadratische Abweichung aller Matrixeinträge und ist ein gängiges Maß für die Rekonstruktionsqualität.

\section{Energieerhaltung der Singulärwerte}
Der Anteil der durch die ersten $k$-Singulärwerte erklärten Energie wird durch:
\begin{verbatim}
    def energy_retained(S: np.ndarray, k: int)
\end{verbatim}
berechnet. Die mathematische Definition lautet:
\[
  E(k) = \frac{\sum_{i=1}^{k} \sigma_i^2}{\sum_{i=1}^{r} \sigma_i^2}
\]
Diese Kennzahl gibt an, wie viel der Gesamtinformation der Originalmatrix durch die Rang-k-Approximation erhalten bleibt. Die Implementierung erfolgt durch:
\begin{verbatim}
     k = min(k, len(S))
    total = np.sum(S ** 2)
    if total == 0:
        return 0.0
    return np.sum(S[:k] ** 2) / total
\end{verbatim}

\section{Berechnung der Speicherersparnis}
Die Speicherersparnis wird durch die Funktion:
\begin{verbatim}
    def storage_savings(m: int, n: int, k: int)
\end{verbatim}
berechnet.

Originalmatrix:
\[
  O = m \times n 
\]
Speicherbedarf der Rang-k-Approximation:
\[
  S(k) = k(m + n + 1)
\]
Relative Speicherersparnis:
\[ 
  E(k) = 1- \frac{S(k)}{O} = 1 - \frac{k(m + n + 1)}{m \times n}
\]
Die Implementierung erfolgt durch:
\begin{verbatim}
    original = m * n
    svd = k * (m + n + 1)
    savings = 1 - svd / original
\end{verbatim}

\section{Darstellung als Graustufenbild}
Letztlich werden die rekonstruierten Matrizen als Graustufenbilder visualisiert. Dies geschieht in der Funktion:
\begin{verbatim}
    def plot_matrix(A: np.ndarray, title: str, savepath: str)
\end{verbatim}
Die Visualisierung erfolgt mit Matplotlib:
\begin{verbatim}
    plt.figure(figsize=(4, 6))
    plt.imshow(A, cmap='gray', aspect='equal')
\end{verbatim}
Die Bilder werden als PNG-Dateien gespeichert, z.B. \texttt{reconstruction\_k\_1.png}, um die visuelle Qualität der Rekonstruktionen für verschiedene $k$-Werte zu visualisieren.

\section{Zentrale Verarbeitung - \texttt{process\_file()}}
Die Funktion:
\begin{verbatim}
    def process_file(
    input_path: str,
    output_dir: str,
    k_values: List[int],
    save_text_recons: bool = True,
    show_plots: bool = False
):
\end{verbatim}
dient als zentrale Pipeline für die gesamte Verarbeitung:
\begin{enumerate}
    \item Erzeugung des Ausgabeordners.
    \item Einlesen der Matrix.
    \item Berechnung der SVD.
    \item Iterative Rekonstruktion für jedes $k$.
    \item Speicherung der PNG-Grafiken.
    \item (Optionale) Speicherung der Textdateien.
    \item Berechnung und Ausgabe der Fehlermaße, Energieerhaltung und Speicherersparnis.
    \item Erstellung einer CSV-Datei mit den Ergebnissen.
    \item (Optionale) Anzeige der Grafiken.
\end{enumerate}
Für jeden k-Wert wird ein vollständiger Datensatz erzeugt.

\section{Ergebnissdatei (CSV)}
Die Datei \texttt{svd\_results.csv} wird im Ausgabeordner gespeichert und enthält eine tabellarische Übersicht aller berechneten Werte für jedes $
k$. Sie enthält folgende Spalten:

\begin{tabular}{l l}
\toprule
\textbf{Spalte} & \textbf{Beschreibung} \\
\midrule
k & Rang der Approximation \\
frobenius\_error & Frobenius-Norm des Rekonstruktionsfehlers \\
energy\_retained & Anteil der durch die ersten $k$-Singulärwerte erklärten Energie \\
original\_values & Speicherbedarf der Originalmatrix \\
svd\_values & Speicherbedarf der Rang-k-Approximation \\
savings\_relative & Relative Speicherersparnis \\
\end{tabular}

Die Datei ermöglicht eine objektive Bewertung der Kompressionsleistung für verschiedene Rangwerte.

\section{Komandzeileninterface (CLI)}
Das Programm wird über ein einfaches CLI gesteuert, das mit der Bibliothek \texttt{argparse} implementiert ist. Es ermöglicht die Angabe folgender Parameter:
\begin{itemize}
    \item \texttt{--input}: Pfad zur Eingabedatei (Standard: \texttt{SVD\_F.txt}).
    \item \texttt{--out}: Verzeichnis für die Ausgabe (Standard: \texttt{svd\_results}).
    \item \texttt{--ks}: Liste der k-Werte für die Rekonstruktion (Standard: 1,2,3,5,8,10).
    \item \texttt{--no-text}: Deaktiviert die Speicherung der Textdateien.
    \item \texttt{--show}: Aktiviert die Anzeige der Grafiken nach der Verarbeitung.
\end{itemize}

\chapter{Auswertung der Ergebnisse}
In diesem Kapitel werden die numerischen Ergebnisse der durchgeführten SVD-Experimente systematisch ausgewertet und interpretiert. Grundlage ist die Datei \texttt{svd\_results.csv}, die für verschiedene Rangwerte 
$k$ die folgenden Kennzahlen enthält: Frobenius-Fehler, Energieerhalt, Original- und SVD-Speicherbedarf sowie die relative Speicherersparnis.

Ziel der Auswertung ist es, (i) die  numerischen Messwerte mathematisch einzuordnen, (ii) den besten Kompromiss zwischen Speicherersparnis und Rekonstruktionsqualität zu identifizieren und (iii) Empfehlungen für die Interpretation und Anwendung der SVD-Kompression abzuleiten.

\section{Datenbasis}
\begin{tabular}{c c c c c c c}
\toprule
\textbf{k} & \textbf{Frobenius-Fehler} & \textbf{Energieerhalt} & \textbf{Original} & \textbf{SVD} & \textbf{Relative Einsparung} \\
\midrule
\
1 & 4.1923 & 79.08\% & 375 & 41  & 89.07\% \\
2 & 1.8278 & 96.02\% & 375 & 82  & 78.13\% \\
3 & $4 \times 10^{-15}$ & 100.00\% & 375 & 123 & 67.20\% \\
5 & $4 \times 10^{-15}$ & 100.00\% & 375 & 205 & 45.33\% \\
8 & $4 \times 10^{-15}$ & 100.00\% & 375 & 328 & 12.53\% \\
10 & $4 \times 10^{-15}$ & 100.00\% & 375 & 410 & -9.33\% \\
\bottomrule
\end{tabular}
\section{Detaillierte numerische Befunde und Interpretation}
\subsection{Frobenius-Fehler}
Aus den Messdaten:

 $k = 1:  \| A - A_1 \|_F \approx 4.1923$

 $k = 2:  \| A - A_2 \|_F \approx 1.8278$

 $k \geq 3:  \| A - A_3 \|_F = 4 \times 10^{-15}$ (numerisch 0)

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{error_vs_k.png}
    \caption{Frobenius-Fehler in Abhängigkeit von k}
    \label{fig:frobenius_error}
\end{figure}

\noindent\textbf{Interpretation:} Die deutliche Fehlerreduktion von $k=1$ zu $k=2$ zeigt, dass die zweite Singulärkomponente  einen erheblichen Teil der Bildinformationen wiedergibt. Ab $k=3$ ist der Fehler praktisch null, was auf eine perfekte Rekonstruktion hinweist. Dies deutet darauf hin, dass die Matrix von \texttt{SVD\_F.txt} einen Rang von 3 besitzt. Anderst gesagt bedeutet das, dass die Originalmatrix exakt als Linearkombination von drei äußeren Produkten $\sigma_i u_i v_i^T$ dargestellt werden kann.


\subsection{Energieerhaltung}

Aus den Messdaten:

 $k = 1:  E(1) \approx 79.08\%$

 $k = 2:  E(2) \approx 96.02\%$

 $k \geq 3:  E(3) = 100.00\%$

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{energy_vs_k.png}
    \caption{Energieerhalt in Abhängigkeit von k}
    \label{fig:energy_retained}
\end{figure}

\noindent\textbf{Interpretation:} Der erste Singulärwert trägt bereits fast 80\% der Gesammtenergie, was bei binären Bildern mit stark konzentrierten Informationen typisch ist. Beim zweiten Wert steigt der Energieerhalt auf über 96\%, damit sind die beiden größten Singulärwerte bereits nahezu vollständig. Ab $k=3$ wird die gesamte Energie erfasst, was im Einklang mit der Rang-3-Eigenschaft der Matrix steht.
Dieses Verhalten ist typisch für strukturierte Bilddaten und wurde bereits frühzeitig für Bildkompression mit SVD genutzt\cite{hansen1987svd}.

\textbf{Folgerung:} Für die vorliegende Matrix ist die Auswahl von $k \geq 3$ äquivalent zur vollständigen Rekonstruktion, während $k=2$ bereits eine gute Näherung bietet.

\break
\subsection{Speicherbedarf und relative Einsparung}
Aus den Messdaten:

Originalmatrix: $O = 15 \times 25 = 375$

$k = 1:  S(1) = 41, \quad E(1) \approx 89.07\%$

$k = 2:  S(2) = 82, \quad E(2) \approx 78.13\%$

$k = 3:  S(3) = 123, \quad E(3) \approx 67.20\%$

$k = 5:  S(5) = 205, \quad E(5) \approx 45.33\%$

$k = 8:  S(8) = 328, \quad E(8) \approx 12.53\%$

$k = 10: S(10) = 410, \quad E(10) \approx -9.33\%$

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{savings_vs_k.png}
    \caption{Relative Speicherersparnis in Abhängigkeit von k}
    \label{fig:storage_savings}
\end{figure}

\noindent\textbf{Interpretation:} Die Speicherersparnis ist bei niedrigen $k$-Werten am größten. Bereits bei $k=1$ werden fast 90\% des Speicherplatzes eingespart, während bei $k=2$ immer noch über 78\% Einsparung erzielt werden. Ab $k=3$ sinkt die Einsparung auf etwa 67\%, was immer noch signifikant ist. Mit zunehmendem $k$ verringert sich die Einsparung rapide, und ab $k=10$ übersteigt der Speicherbedarf der SVD-Rekonstruktion den der Originalmatrix.
Daraus lässt sich ableiten, dass SVD-Kompression nur sinnvoll ist, wenn $S(k) < O$. Daraus ergibt sich eine Höchstgrenze $k_{max}$ für sinnvolle Kompression aus:

\[
    k_{max} < \frac{O}{m + n + 1} = \frac{m \times n}{m + n + 1}
\]
Für die vorliegende Matrix ($m=15$, $n=25$) ergibt sich:
\[
    k_{max} < \frac{375}{41} \approx 9.15
\]
Dies wird von den Ergebnissen bestätigt, da bei $k=10$ die Einsparung negativ wird.

\section{Bestimmung des optimalen k-Werts}
\begin{figure}[H]
  \centering
  \begin{subfigure}{0.15\textwidth}
    \includegraphics[width=\linewidth]{original.png}
    \caption{Original}
  \end{subfigure}
  \begin{subfigure}{0.15\textwidth}
    \includegraphics[width=\linewidth]{reconstruction_k_1.png}
    \caption{$k=1$}
  \end{subfigure}
    \begin{subfigure}{0.15\textwidth}
        \includegraphics[width=\linewidth]{reconstruction_k_2.png}
        \caption{$k=2$}
    \end{subfigure}
  \begin{subfigure}{0.15\textwidth}
    \includegraphics[width=\linewidth]{reconstruction_k_3.png}
    \caption{$k=3$}
  \end{subfigure}
  \begin{subfigure}{0.15\textwidth}
    \includegraphics[width=\linewidth]{reconstruction_k_5.png}
    \caption{$k=5$}
  \end{subfigure}
  \caption{Originalbild und Rekonstruktionen}
  \label{fig:recons}
\end{figure}

Die Antwort auf die Frage nach dem optimalen $k$-Wert hängt von den spezifischen Anforderungen an Speicherplatz und Rekonstruktionsqualität ab. Basierend auf den vorliegenden Ergebnissen lassen sich folgende Empfehlungen ableiten:
\begin{itemize}
    \item Für Anwendungen, die eine nahezu perfekte Rekonstruktion erfordern, ist $k=3$ optimal, da hier die Originalmatrix exakt wiederhergestellt wird und dennoch eine Speicherersparnis von über 67\% erzielt wird.
    \item Für Szenarien, in denen Speicherplatz eine kritische Rolle spielt und eine leichte Qualitätsminderung akzeptabel ist, bietet $k=2$ einen hervorragenden Kompromiss mit über 78\% Speicherersparnis und einem Frobenius-Fehler von nur etwa 1.8278.
    \item $k=1$ kann in sehr speicherbeschränkten Umgebungen verwendet werden, wobei jedoch ein deutlicher Qualitätsverlust in Kauf genommen werden muss und der Informationswert stark eingeschränkt ist.
\end{itemize}
Rekonstruktionen mit $k > 3$ sind in diesem Fall nicht sinnvoll, da sie keinen Qualitätsgewinn bringen und den Speicherbedarf unnötig erhöhen.

\section{Numerische Genauigkeit und Stabilität}
Die bei $k \geq 3$ beobachteten numerischen Fehler von $4 \times 10^{-15}$ sind auf die begrenzte Genauigkeit der Gleitkommadarstellung in Computern zurückzuführen\cite{trefethen_bau}. Diese Werte sind vernachlässigbar und bestätigen die Stabilität der SVD-Methode für die vorliegende Matrix.

\chapter{Fazit}
Diese Hausarbeit hat die Singulärwertzerlegung (SVD) als mathematisches Werkzeug zur Daten- und Bildkompression theoretisch hergeleitet, praktisch implementiert und umfassend ausgewertet. Das Ziel war es, den Zusammenhang zwischen Rang-k-Ap-proximation, Rekonstruktionsqualität und Speicherersparnis zu verstehen.

Die durchgeführten Experimente mit der binären Matrix des Buchstabens „F“ zeigten, dass diese den Rang 3 besitzt. Bereits mit drei Singulärwerten konnte die Originalmatrix exakt rekonstruiert werden. Gleichzeitig wurde trotzdem eine signifikante Speicherersparnis von über 67\% erzielt. Die Analyse der Frobenius-Norm des Rekonstruktionsfehlers bestätigte die hohe Qualität der Approximationen, insbesondere für $k=2$ und $k=3$.

Besonders hervorzuheben ist die starke Konzentration der Bildinformation in den ersten beiden Singulärwerten. Mit nur zwei Werten konnte bereits über 96\% der Gesamtenergie erfasst werden. Dies unterstreicht die Effektivität der SVD bei der Reduktion von stark strukturierter Daten.

Die Analyse der Speicherersparnis zeigte, dass die SVD-basierte Speicherung nur dann vorteilhaft ist, wenn der Rang $k$ klein im Verhältnis zu den Matrixdimensionen $m$ und $n$ ist. Für zu große Werte von $k$ übersteigt der Speicherbedarf der SVD-Rekonstruktion sonst den der Originalmatrix. Dies unterstreicht die Notwendigkeit einer sorgfältigen Wahl des Kompressionsgrades basierend auf den spezifischen Anforderungen an Speicherplatz und Rekonstruktionsqualität.

Zusammenfassend konnte gezeigt werden, dass die SVD ein mächtiges Werkzeug für die Bildkompression darstellt. Sie ermöglicht es, je nach Anforderungen, einen optimalen Kompromiss zwischen Speicherersparnis und Bildqualität zu finden. Die verbindung aus solider mathematischer Theorie, effizienter Implementierung und systematischer Auswertung macht die SVD zu einem unverzichtbaren Verfahren in zahlreichen Anwendungsbereichen der Datenverarbeitung.

\break
\printbibliography[heading=bibintoc,title=Literatur]
\newpage

% --- Abbildungsverzeichnis: KEIN \addcontentsline nötig ---
%\begingroup
%  \listoffigures
%\endgroup
%\newpage

% Listingsverzeichnis: weiterhin expliziter ToC-Eintrag
%\phantomsection\addcontentsline{toc}{chapter}{\lstlistlistingname}
%\begingroup
%  \lstlistoflistings
%\endgroup
%\newpage

%\phantomsection\addcontentsline{toc}{chapter}{\glossaryname}
%\begingroup
%  \printglossary[title=\glossaryname]
%\endgroup
%\newpage

%\\phantomsection\addcontentsline{toc}{chapter}{Abkürzungsverzeichnis}
%\\begingroup
%\  \printglossary[type=\acronymtype,title=Abkürzungsverzeichnis]
%\\endgroup
%\\newpage

% --- Tabellenverzeichnis: KEIN \addcontentsline nötig ---
%\\begingroup
%\  \listoftables
%\\endgroup
%\\newpage

%\\appendix

\phantomsection\addchap{Anhang}

\phantomsection\addsec{Selbstständigkeitserklärung}
Ich versichere, dass ich die vorliegende Hausarbeit ohne fremde Hilfe selbstständig verfasst und nur die angegebenen Quellen und Hilfsmittel benutzt habe. Wörtlich oder dem Sinn nach aus anderen Werken entnommene Stellen sind unter Angabe der Quellen kenntlich gemacht. Bestandteile der Arbeit, die mittels künstlicher Intelligenz entstanden sind, wurden ausdrücklich gekennzeichnet. Die Arbeit wurde bisher in gleicher oder ähnlicher Form weder veröffentlicht noch einer anderen Prüfungsbehörde vorgelegt.\\[2em]
Bitterfeld, 23. Dezember 2025 \hfill\rule{5cm}{0.4pt}
\noindent\makebox[\linewidth][r]{Malte Luca Peukert}\par

\end{document}